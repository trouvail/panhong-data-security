Deep neural networks have strong capabilities of memorizing the underlying training data, which can be a serious privacy concern. An efective solution to this problem is to train models with differential privacy (DP), which provides rigorous privacy guarantees by injecting random noise to the gradients. This paper focuses on the scenario where sensitive data are distributed among multiple participants, who jointly train a model through federated learning, using both secure multiparty computation (MPC) to ensure the confdentiality of each gradient update, and diferential privacy to avoid data leakage in the resulting model. A major challenge in this setting is that common mechanisms for enforcing DP in deep learning, which inject real-valued noise, are fundamentally incompatible with MPC, which exchanges fnite-feld integers among the participants. Consequently, most existing DP mechanisms require rather high noise levels, leading to poor model utility.
深度神经网络具有强大的记忆底层训练数据的能力，这可能是一个严重的隐私问题。该问题的有效解决方案是训练具有差分隐私（DP）的模型，该模型通过向梯度注入随机噪声来提供严格的隐私保证。本文重点讨论了敏感数据分布在多个参与者之间的场景，这些参与者通过联合学习联合训练模型，使用安全多方计算（MPC）来确保每个梯度更新的一致性，并使用不同的隐私来避免生成的模型中的数据泄露。这一集合中的一个主要挑战是，在深度学习中执行DP的常见机制（注入实值噪声）与MPC（在参与者之间交换fnite-feld整数）根本不兼容。因此，大多数现有的DP机制需要相当高的噪声水平，导致模型实用性差。

Motivated by this, we propose Skellam mixture mechanism (SMM), a novel approach to enforcing DP on models built via federated learning. Compared to existing methods, SMM eliminates the assumption that the input gradients must be integer-valued, and, thus, reduces the amount of noise injected to preserve DP. The theoretical analysis of SMM is highly non-trivial, especially considering (i) the complicated math of DP deep learning in general and (ii) the fact that the mixture of two Skellam distributions is rather complex. Extensive experiments on various practical settings demonstrate that SMM consistently and signifcantly outperforms existing solutions in terms of the utility of the resulting model.
受此启发，我们提出了Skellam混合机制（SMM），这是一种在通过前馈学习建立的模型上执行DP的新方法。与现有方法相比，SMM消除了输入梯度必须是整数值的假设，从而减少了为保持DP而注入的噪声量。SMM的理论分析是非常不平凡的，特别是考虑到（i）DP深度学习的复杂数学，以及（ii）两个Skellam分布的混合相当复杂。在各种实际环境中进行的大量实验表明，就所得模型的效用而言，SMM始终显著优于现有解决方案。


